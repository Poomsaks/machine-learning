import os
import joblib
import numpy as np
from flask import Flask, jsonify, request
from pathlib import Path

# --- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Flask ---
app = Flask(__name__)

# --- ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Path (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏≤ Model ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠) ---
# ‡∏î‡∏∂‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Folder ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏ü‡∏•‡πå app.py ‡∏ô‡∏µ‡πâ‡∏ß‡∏≤‡∏á‡∏≠‡∏¢‡∏π‡πà
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / "knn_model.joblib"
SCALER_PATH = BASE_DIR / "scaler.pkl"

# Global Variables ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö Model
model = None
scaler = None

def load_ml_assets():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î Model ‡πÅ‡∏•‡∏∞ Scaler ‡πÄ‡∏°‡∏∑‡πà‡∏≠ Start Server"""
    global model, scaler
    
    print("-" * 30)
    print(f"üöÄ Starting System at: {BASE_DIR}")
    
    # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Model
    if MODEL_PATH.exists():
        try:
            model = joblib.load(MODEL_PATH)
            print(f"‚úÖ SUCCESS: Loaded Model from {MODEL_PATH}")
        except Exception as e:
            print(f"‚ùå ERROR: Failed to load model: {e}")
    else:
        print(f"‚ùå ERROR: Model file NOT FOUND at {MODEL_PATH}")
        print(f"üìÅ Available files in directory: {os.listdir(BASE_DIR)}")

    # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Scaler (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
    if SCALER_PATH.exists():
        try:
            scaler = joblib.load(SCALER_PATH)
            print(f"‚úÖ SUCCESS: Loaded Scaler from {SCALER_PATH}")
        except Exception as e:
            print(f"‚ö†Ô∏è WARNING: Found scaler but failed to load: {e}")
    else:
        print(f"‚ÑπÔ∏è INFO: Scaler not found, system will skip scaling.")
    
    print("-" * 30)

# ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏´‡∏•‡∏î Assets ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
load_ml_assets()

# --- API Routes ---

@app.route('/')
def home():
    """Route ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Ç‡∏≠‡∏á Server"""
    return jsonify({
        "status": "online",
        "model_loaded": model is not None,
        "scaler_loaded": scaler is not None,
        "api_version": "1.0.0"
    })

@app.route('/predict', methods=['POST'])
def predict():
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Å‡πà‡∏≠‡∏ô‡∏ß‡πà‡∏≤‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏´‡∏°
    if model is None:
        return jsonify({
            "error": "Model is not loaded on the server. Please check file path or server logs.",
            "path_searched": str(MODEL_PATH)
        }), 500
    
    try:
        data = request.get_json()
        if not data:
            return jsonify({"error": "No data provided"}), 400

        features = None
        
        # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 2 ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö (‡πÅ‡∏ö‡∏ö Array ‡∏´‡∏£‡∏∑‡∏≠ ‡πÅ‡∏ö‡∏ö Object)
        if 'data' in data and isinstance(data['data'], list):
            features = data['data']
        
        elif 'features' in data:
            f = data['features']
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö Feature ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà Model ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (15 ‡∏ï‡∏±‡∏ß)
            feature_keys = [
                'bps', 'bpd', 'bw', 'height', 'fbs', 'bmi', 'tg', 'hdl', 
                'creatinine', 'hba1c', 'fh', 'waist', 'smoking_type_id', 
                'drinking_type_id', 'egfr'
            ]
            try:
                features = [float(f.get(k, 0)) for k in feature_keys]
            except (ValueError, TypeError):
                return jsonify({"error": "Feature values must be numeric"}), 400

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Feature (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô 15)
        if not features or len(features) != 15:
            return jsonify({
                "error": f"Invalid input. Expected 15 features, received {len(features) if features else 0}"
            }), 400

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô NumPy Array ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Predict
        input_data = np.array(features).reshape(1, -1)
        
        # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ Scaler ‡πÉ‡∏´‡πâ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Transform ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô
        if scaler is not None:
            input_data = scaler.transform(input_data)

        # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ú‡∏•
        prediction = model.predict(input_data)[0]
        result_text = "‡πÄ‡∏õ‡πá‡∏ô" if prediction == 1 else "‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô"
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô (‡∏ñ‡πâ‡∏≤ Model ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö)
        confidence = None
        if hasattr(model, 'predict_proba'):
            probs = model.predict_proba(input_data)[0]
            confidence = float(probs[prediction])

        return jsonify({
            "status": "success",
            "prediction": result_text,
            "raw_value": int(prediction),
            "confidence": confidence,
            "input_received": features
        })

    except Exception as e:
        print(f"‚ùå Runtime Error: {e}")
        return jsonify({"error": "An internal error occurred during prediction"}), 500

if __name__ == '__main__':
    # ‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Port 6000
    # ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥: ‡πÉ‡∏ä‡πâ debug=False ‡πÉ‡∏ô‡πÇ‡∏õ‡∏£‡∏î‡∏±‡∏Å‡∏ä‡∏±‡πà‡∏ô ‡πÅ‡∏ï‡πà‡πÉ‡∏ä‡πâ debug=True ‡∏ï‡∏≠‡∏ô‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
    app.run(host='0.0.0.0', port=6000, debug=True)